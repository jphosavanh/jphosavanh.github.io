[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Johnson Phosavanh",
    "section": "",
    "text": "I am final year PhD candidate at the Discipline of Business Analytics at the University of Sydney, supervised by Professor Daniel Oron and Dr Nam Ho-Nguyen. My research area is combinatorial optimization with a particular focus on scheduling theory and optimization with graphs."
  },
  {
    "objectID": "index.html#about-me",
    "href": "index.html#about-me",
    "title": "Johnson Phosavanh",
    "section": "",
    "text": "I am final year PhD candidate at the Discipline of Business Analytics at the University of Sydney, supervised by Professor Daniel Oron and Dr Nam Ho-Nguyen. My research area is combinatorial optimization with a particular focus on scheduling theory and optimization with graphs."
  },
  {
    "objectID": "index.html#education",
    "href": "index.html#education",
    "title": "Johnson Phosavanh",
    "section": "Education",
    "text": "Education\nDoctor of Philosophy (Business)  The University of Sydney Jul 2022 — Dec 2025\n\nThesis title: Dynamic scheduling problems.\n\nBachelor of Advanced Studies (Honours)  The University of Sydney Feb 2021 — Dec 2021\n\nFirst Class Honours with University Medal.\nHonours in Business Analytics.\n\nBachelor of Science  The University of Sydney Feb 2018 — Dec 2020\n\nMajors in Business Analytics and Data Science."
  },
  {
    "objectID": "index.html#research",
    "href": "index.html#research",
    "title": "Johnson Phosavanh",
    "section": "Research",
    "text": "Research\n\nPeer reviewed articles\n\nPhosavanh J., Matsypura, D. (2025). Centrality of shortest paths: algorithms and complexity results. To appear in the INFORMS Journal on Computing.\n\n\n\nAbstract\n\n\n\n\nThe centrality of a node is often used to measure its importance to the structure of a network. Some centrality measures can be extended to measure the importance of a path. In this paper, we consider the problem of finding the most central shortest path. We show that the computational complexity of this problem depends on the measure of centrality used and, in the case of degree centrality, whether the network is weighted or not. We develop a polynomial algorithm for the most degree-central shortest path problem with the worst-case running time of \\(O(|E||V|^2\\Delta(G))\\), where \\(|V|\\) is the number of vertices in the network, \\(|E|\\) is the number of edges in the network, and \\(\\Delta(G)\\) is the maximum degree of the graph. In addition, we show that the same problem is NP-hard on a weighted graph. Furthermore, we show that the problem of finding the most betweenness-central shortest path is solvable in polynomial time, while finding the most closeness-central shortest path is NP-hard, regardless of whether the graph is weighted or not. We also develop an algorithm for finding the most betweenness-central shortest path with a running time of \\(O(|E|^2|V|^2)\\) on unweighted graphs and \\(O(|E|^2|V|^2 + |V|^2\\log(|V|))\\) on graphs with positively weighted edges. To conclude our paper, we conduct a numerical study of our algorithms on synthetic and real-world networks and compare our results to the existing literature.\n\n\n\nPhosavanh J., Oron, D. (2025). Single-machine two-agent scheduling with a rate-modifying activity and weighted due-date-related functions. Journal of Scheduling. 10.1007/s10951-025-00853-0.\n\n\n\nAbstract\n\n\nBibTeX\n\n\n\n\nWe analyze two-agent scheduling problems with weighted due-date-related scheduling criteria and an optional rate-modifying activity that, when completed, allows jobs to be completed faster. We start with the single-agent problem of minimizing the total weighted late work and then extend the results over to two-agent problems involving combinations of the weighted number of late jobs and the total weighted late work. We examine the properties of optimal schedules and provide efficient pseudo-polynomial time algorithms to solve these problems.\n\n\n\n@article{PhosavanhOron2025JoSH,\ntitle = {Single-machine two-agent scheduling with a rate-modifying activity and weighted due-date-related functions},\njournal = {Journal of Scheduling},\nyear = {2025},\ndoi = {10.1007/s10951-025-00853-0},\nauthor = {Johnson Phosavanh and Daniel Oron},\nkeywords = {Two-agent scheduling, Single-machine, Rate-modifying activity, Dynamic programming},\n}\n\n\nPhosavanh J., Oron, D. (2025). Minimizing the number of late jobs and total late work with step-learning. European Journal of Operational Research, 321(3), 734–749. https://doi.org/10.1016/j.ejor.2024.09.042.\n\n\n\nAbstract\n\n\nBibTeX\n\n\n\n\nWe study single-machine scheduling problems with step-learning, where an improvement in processing time is experienced if a job is started at, or after, a job-dependent learning-date. We consider minimizing two functions: the number of late jobs and the total late work, and we show that when at least a common due-date or common learning-date is assumed, the problem is \\(\\mathcal{NP}\\)-hard in the ordinary sense; however, when both are arbitrary, the problem becomes strongly \\(\\mathcal{NP}\\)-hard. For each of the problems where at least one of the dates is assumed to be common, we analyze the structure of an optimal job schedule with and without idle time and propose pseudo-polynomial time dynamic programming algorithms. We also show that the problem of minimizing the weighted number of late jobs with step-learning can be solved with a minor change to the algorithms for the unweighted case. In addition to this, we show that when a common due-date is assumed and no idle time is allowed, the problem of minimizing the total late work is equivalent to that of minimizing the makespan. Furthermore, we provide a more efficient algorithm to solve the problem of minimizing makespan under the assumption of a common learning-date than the one in the existing literature. Lastly, we show that our analysis can also be applied to the case of step-deterioration, where instead, the processing times of jobs increase at a given date.\n\n\n\n\n@article{PhosavanhOron2025EJOR,\ntitle = {Minimizing the number of late jobs and total late work with step-learning},\njournal = {European Journal of Operational Research},\nyear = {2025},\nissn = {0377-2217},\nvolume = {321},\nnumber = {3},\npages = {734-749},\ndoi = {10.1016/j.ejor.2024.09.042},\nauthor = {Johnson Phosavanh and Daniel Oron},\nkeywords = {Scheduling, Single-machine, Step-learning, Dynamic programming},\n}\n\n\nPhosavanh J., Oron, D. (2024). Two-agent single-machine scheduling with a rate-modifying activity. European Journal of Operational Research, 312(3), 866–876. http://doi.org/10.1016/j.ejor.2023.08.002.\n\n\n\nAbstract\n\n\nBibTeX\n\n\n\n\nWe study single-machine scheduling problems involving a rate-modifying activity and two competing agents with due-date-related functions. Classical scheduling models assume that job processing times remain constant over time; however, in real-world settings, processing times may change due to factors such as technological upgrades or machine maintenance. We complement this with the notion of multiple independent agents competing over the use of a shared resource, each with their own motives. These considerations allow us to model the upcoming trend of the sharing economy, where resources are shared amongst independent competitors in the market. We aim to model these scenarios by considering a variety of scheduling criteria for each agent, including the makespan, the number of late jobs, and the total late work. To account for the change in processing times, we consider an optional rate-modifying activity that once completed, results in a reduction in subsequent job processing times. We show that problems involving the total late work are binary \\(\\mathcal{NP}\\)-hard and propose efficient pseudo-polynomial dynamic programming algorithms for solving these problems. We also show that the remaining problems are solvable in polynomial time.\n\n\n\n\n@article{PhosavanhOron2024,\ntitle = {Two-agent single-machine scheduling with a rate-modifying activity},\njournal = {European Journal of Operational Research},\nyear = {2024},\nvolume = {312},\npages = {866-876},\nnumber = {3},\nissn = {0377-2217},\ndoi = {10.1016/j.ejor.2023.08.002},\nauthor = {Johnson Phosavanh and Daniel Oron},\nkeywords = {Scheduling, Single machine, Two-agents, Dynamic programming},\n}\n\n\n\n\n\nArticles under review\n\nPhosavanh J., Oron, D. (2025). Minimizing total weighted late work with step-learning on a single machine. Submitted to Discrete Applied Mathematics (1st round R&R).\n\n\n\nAbstract\n\n\n\n\nWe study single-machine scheduling problems with step-learning to minimize the total weighted late work. Step-learning is a mechanism that allows jobs to be completed more efficiently if started after a job-dependent learning-date. We show that this problem is strongly \\(\\mathcal{NP}\\)-hard when both learning-dates and due-dates are arbitrary, but when at least one is assumed to be the same for all jobs, the problem is \\(\\mathcal{NP}\\)-hard in the ordinary sense, and we provide pseudo-polynomial algorithms for these cases.\n\n\n\n\n\n\nConferences\n\nPhosavanh J., Oron, D. (2025, June 22 – 25). Single-machine scheduling with cooperative agents and nondisjoint job sets. 34th European Conference on Operational Research (EURO 2025), Leeds, United Kingdom.\nPhosavanh J., Oron, D. (2024, December 4 – 6). Minimizing the number of late jobs and total late work with step-learning. Workshop on Optimisation, Metric Bounds, Approximation and Transversality (WOMBAT), Sydney, NSW, Australia.\nPhosavanh J., Oron, D. (2024, October 20 – 23). Minimizing the number of late jobs and total late work with step-learning. 2024 INFORMS Annual Meeting, Seattle, WA, United States of America.\nPhosavanh J., Oron, D. (2024, June 30 – July 3). Minimizing the number of late jobs and total late work with step-learning. 33rd European Conference on Operational Research (EURO 2024), Copenhagen, Denmark.\nPhosavanh J., Matsypura, D. (2023, December 11 – 16). Finding the most central shortest path in a graph. Joint Workshop on Optimisation, Metric Bounds, Approximation and Transversality (WOMBAT) and Workshop on the Intersections of Computation and Optimisation (WICO), Sydney, NSW, Australia.\nPhosavanh J., Matsypura, D. (2023, October 15 – 18). Finding the most central shortest path in a graph. 2023 INFORMS Annual Meeting, Phoenix, AZ, United States of America.\nPhosavanh J., Oron, D. (2023, June 5 – 6). Single-machine scheduling with two competing agents and rate-modifying activities with weighted due-date related functions. The Fourth International Workshop on Dynamic Scheduling Problems (IWDSP 2023), Winterthur, Switzerland.\nPhosavanh J., Oron, D. (2022, December 6 – 9). Two-agent single-machine scheduling with a rate-modifying activity. 66th Annual Meeting of the Australian Mathematical Society (AustMS), Sydney, NSW, Australia."
  },
  {
    "objectID": "index.html#teaching",
    "href": "index.html#teaching",
    "title": "Johnson Phosavanh",
    "section": "Teaching",
    "text": "Teaching\nThe University of Sydney\n\nQBUS1040: Foundations of Business Analytics\n\nCoordinator & Lecturer: Semester 1, 2025 – Semester 2, 2025\nHead tutor: Semester 1, 2022 – Semester 2, 2024\nTutor: Semester 2, 2021\nLab demonstrator: Semester 1, 2019 – Semester 1, 2021\n\nQBUS2310: Management Science\n\nHead tutor: Semester 1, 2022 – Semester 2, 2024\n\nQBUS6820: Prescriptive Analytics: From Data to Decision\n\nHead tutor: Semester 1, 2023\n\nDATA1001: Foundations of Data Science\n\nLab demonstrator: Semester 1, 2020 – Semester 2, 2020\n\nMATH1005: Statistical Thinking with Data\n\nLab demonstrator: Semester 2, 2020"
  },
  {
    "objectID": "index.html#scholarships-awards",
    "href": "index.html#scholarships-awards",
    "title": "Johnson Phosavanh",
    "section": "Scholarships & Awards",
    "text": "Scholarships & Awards\n\nResearch\n\nEnhanced Business School Research Scholarship, 2022 – 2025.\nPostgraduate Research Support Scheme, 2025.\nDiscipline of Business Analytics Student Paper Prize Winner, 2024.\nPostgraduate Research Support Scheme, 2024.\nResearch Travel Support Scheme, 2024.\nResearch Travel Support Scheme, 2023.\nThe Westbrook and Jessie Anstice Honours Scholarship in Business, 2021.\nDenison Research Scholarship, 2019 – 2020.\n\n\n\nTeaching\n\n2024 Dean’s Award for Feedback for Teaching (FFT).\n\nAwarded in recognition of outstanding performance tof an individual instructor demonstrating and reflecting upon exceptional teaching.\n\nFeedback for Teaching (FFT) Student Survey Award for Teaching.\n\nAwarded in recognition of individual instructors based on high overall evaluations from students on the FFT:\n\nQBUS1040, Semester 1, 2024.\nQBUS2310, Semester 1, 2024.\nQBUS1040, Semester 2, 2023.\n\n\n2022 Discipline of Business Analytics Teaching Excellence Award.\n\nAwarded in recognition of outstanding achievement in teaching within the Discipline of Business Analytics.\n\n\n\n\nAcademic\n\nUniversity of Sydney Academic Merit Prize, 2021.\nDean’s List of Excellence in Academic Performance, 2021.\nUniversity of Sydney Academic Merit Prize, 2020.\nDean’s List of Excellence in Academic Performance, 2020.\nUniversity of Sydney Academic Merit Prize, 2019.\nDiscipline of Business Analytics Prize in 2nd year Quantitative Business: 2019.\nTim Brown Prize No 1 for Intermediate Statistics, 2019.\nDean’s List of Excellence in Academic Performance, 2019.\nDean’s List of Excellence in Academic Performance, 2018."
  },
  {
    "objectID": "teaching-visualisations/constrained-least-squares.html",
    "href": "teaching-visualisations/constrained-least-squares.html",
    "title": "VMLS: Constrained least squares",
    "section": "",
    "text": "The data for this plot comes from Introduction to Applied Linear Algebra – Vectors, Matrices, and Least Squares (Boyd and Vandenberghe, 2018)."
  },
  {
    "objectID": "teaching-visualisations/constrained-least-squares.html#references",
    "href": "teaching-visualisations/constrained-least-squares.html#references",
    "title": "VMLS: Constrained least squares",
    "section": "References",
    "text": "References\nBoyd, S. P., & Vandenberghe, L. (2018). Introduction to Applied Linear Algebra : Vectors, Matrices, and Least Squares (First edition.). Cambridge University Press."
  },
  {
    "objectID": "teaching-visualisations/lighting-problem.html",
    "href": "teaching-visualisations/lighting-problem.html",
    "title": "VMLS: Lighting problem",
    "section": "",
    "text": "The data for this plot comes from Introduction to Applied Linear Algebra – Vectors, Matrices, and Least Squares (Boyd and Vandenberghe, 2018)."
  },
  {
    "objectID": "teaching-visualisations/lighting-problem.html#references",
    "href": "teaching-visualisations/lighting-problem.html#references",
    "title": "VMLS: Lighting problem",
    "section": "References",
    "text": "References\nBoyd, S. P., & Vandenberghe, L. (2018). Introduction to Applied Linear Algebra : Vectors, Matrices, and Least Squares (First edition.). Cambridge University Press."
  },
  {
    "objectID": "teaching-visualisations/least-squares.html",
    "href": "teaching-visualisations/least-squares.html",
    "title": "VMLS: Least squares",
    "section": "",
    "text": "The data for this plot comes from Introduction to Applied Linear Algebra – Vectors, Matrices, and Least Squares (Boyd and Vandenberghe, 2018)."
  },
  {
    "objectID": "teaching-visualisations/least-squares.html#references",
    "href": "teaching-visualisations/least-squares.html#references",
    "title": "VMLS: Least squares",
    "section": "References",
    "text": "References\nBoyd, S. P., & Vandenberghe, L. (2018). Introduction to Applied Linear Algebra : Vectors, Matrices, and Least Squares (First edition.). Cambridge University Press."
  },
  {
    "objectID": "teaching-visualisations/regularisation.html",
    "href": "teaching-visualisations/regularisation.html",
    "title": "VMLS: Regularisation",
    "section": "",
    "text": "#| '!! shinylive warning !!': |\n#|   shinylive does not work in self-contained HTML documents.\n#|   Please set `embed-resources: false` in your metadata.\n#| standalone: true\n#| viewerHeight: 620\n\nfrom shiny import App, render, ui, reactive\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef vandermonde(t, n):\n    m = t.shape[0]\n    A = np.zeros((m, n))\n\n    for j in range(m):\n        for i in range(n):\n            A[j, i] = t[j]**i\n\n    return A\n\ndef rms(y):\n    return np.linalg.norm(y) / np.sqrt(y.shape[0])\n\nnp.random.seed(10)\nN_train = 10\nx_train = np.random.uniform(low=-3, high=3, size=N_train)\ntrue = np.array([-3, -2.7, -2, 0.8, 0.5])\ndeg1 = true.shape[0]\ny_train = vandermonde(x_train, deg1) @ true + np.random.normal(scale=3, size=N_train)\n\nN_test = 20\nx_test = np.random.uniform(low=-3, high=3, size=N_test)\ny_test = vandermonde(x_test, deg1) @ true + np.random.normal(scale=3, size=N_test)\n\nx_plot = np.linspace(np.min(np.concatenate([x_train, x_test])), np.max(np.concatenate([x_train, x_test])))\nA_plot = vandermonde(x_plot, deg1)\ny_true = A_plot @ true\n\nL = 1000\nlambdas = 10**np.linspace(-4, 7, L)\ntheta_hats = np.zeros((L, deg1))\n\nA_train = vandermonde(x_train, deg1)\nA_test = vandermonde(x_test, deg1)\n\nrms_train = np.zeros(L)\nrms_test = np.zeros(L)\nJ1 = np.zeros(L)\nJ2 = np.zeros(L)\n\nfor i in range(L):\n    lamb = lambdas[i]\n    A_reg = np.sqrt(lamb)*np.eye(deg1)\n    A_reg = A_reg[1:]\n    A_tilde = np.concatenate((A_train, A_reg), axis=0)\n    zeros = np.zeros(deg1-1)\n    y_tilde = np.concatenate((y_train, zeros))\n    theta_hat = np.linalg.pinv(A_tilde) @ y_tilde\n\n    rms_train[i] = rms(A_train @ theta_hat - y_train)\n    rms_test[i] = rms(A_test @ theta_hat - y_test)\n\n    theta_hats[i] = theta_hat\n\n    J1[i] = np.linalg.norm(A_train @ theta_hat - y_train) ** 2\n    J2[i] = np.linalg.norm(theta_hat[1:]) ** 2\n\napp_ui = ui.page_fluid(\n    ui.layout_sidebar(\n        ui.sidebar(\n            ui.input_slider('lamb', '10^λ', min=-4, max=7, value=-4, step = 0.1)\n        ),\n        ui.layout_columns(\n        ui.card(\n            ui.output_plot(\"mainplot\", height=\"240px\"),\n            ui.output_plot(\"pareto_plot\", height=\"240px\"), \n        ),\n        ui.card(\n            ui.output_plot(\"shrinkage_plot\", height=\"240px\"),\n            ui.output_plot(\"error_plot\", height=\"240px\"), \n        ),\n        ),\n    ),\n)\n\n\ndef server(input, output, session):\n\n    @render.plot\n    def mainplot():\n        A_reg = np.sqrt(10**input.lamb())*np.eye(deg1)\n        A_reg = A_reg[1:]\n        A_tilde = np.concatenate((A_train, A_reg), axis=0)\n        zeros = np.zeros(deg1-1)\n        y_tilde = np.concatenate((y_train, zeros))\n        theta_hat = np.linalg.pinv(A_tilde) @ y_tilde\n\n        fig, ax = plt.subplots()\n        ax.scatter(x_train, y_train, label='Training')\n        ax.scatter(x_test, y_test, label='Test')\n        ax.plot(x_plot, y_true, c='black', label='True')\n        ax.plot(x_plot, A_plot @ theta_hat, c='red', label='Fitted', linewidth=4)\n        ax.legend()\n\n        return fig\n\n    # ========================================================================\n\n    @render.plot\n    def pareto_plot():\n        A_reg = np.sqrt(10**input.lamb())*np.eye(deg1)\n        A_reg = A_reg[1:]\n        A_tilde = np.concatenate((A_train, A_reg), axis=0)\n        zeros = np.zeros(deg1-1)\n        y_tilde = np.concatenate((y_train, zeros))\n        theta_hat = np.linalg.pinv(A_tilde) @ y_tilde\n\n        j1 = np.linalg.norm(A_train @ theta_hat - y_train) ** 2\n        j2 = np.linalg.norm(theta_hat[1:]) ** 2\n\n        fig, ax = plt.subplots()\n        ax.plot(J1, J2)\n        ax.vlines(j1, 0, j2, color='black')\n        ax.hlines(j2, 0, j1, color='black')\n        ax.set_xscale('log')\n        ax.set_xlabel('J1')\n        ax.set_ylabel('J2')\n        return fig\n\n    # ========================================================================\n\n    @render.plot\n    def shrinkage_plot():\n        fig, ax = plt.subplots()\n        cols = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b', '#e377c2', '#7f7f7f', '#bcbd22', '#17becf']\n        for i in range(deg1):\n            ax.plot(lambdas, theta_hats[:, i], label='$\\\\theta_{}$'.format(i+1))\n            ax.axhline(true[i], c=cols[i], linestyle='dashed')\n\n        ax.axvline(10**input.lamb(), c='black', linestyle='dashed')\n        ax.set_xlabel('$\\\\lambda$')\n        ax.set_ylabel('$\\\\theta$')\n        ax.set_xscale('log')\n        ax.legend()\n        return fig\n\n    # ========================================================================\n\n    @render.plot\n    def error_plot():\n        fig, ax = plt.subplots()\n        ax.plot(lambdas, rms_train, label='Train error')\n        ax.plot(lambdas, rms_test, label='Test error')\n        ax.axvline(10**input.lamb(), c='black', linestyle='dashed')\n        ax.set_xscale('log')\n        ax.set_xlabel('$\\\\lambda$')\n        ax.set_ylabel('RMS Error')\n        ax.legend()\n        return fig\n\n\napp = App(app_ui, server)"
  }
]